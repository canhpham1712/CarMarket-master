"""
Script ƒë·ªÉ retrain nhi·ªÅu model, so s√°nh v√† l∆∞u model t·ªët nh·∫•t v·ªõi scikit-learn hi·ªán t·∫°i
"""
import joblib
import os
from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

print("üîÑ RETRAIN NHI·ªÄU MODEL V√Ä CH·ªåN MODEL T·ªêT NH·∫§T")
print("\n" + "="*60)

# Ki·ªÉm tra XGBoost
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("‚ö†Ô∏è XGBoost kh√¥ng c√≥ s·∫µn, s·∫Ω b·ªè qua model n√†y")

# ƒê∆∞·ªùng d·∫´n
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"

# T√¨m file data ƒë√£ l√†m s·∫°ch ho·∫∑c file merged
cleaned_file = DATA_DIR / "toyota_cleaned.csv"
if cleaned_file.exists():
    data_file = cleaned_file
    print(f"\nüìÅ ƒêang ƒë·ªçc d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch t·ª´: {data_file.name}")
else:
    data_files = list(DATA_DIR.glob("toyota_merged*.csv"))
    if not data_files:
        raise FileNotFoundError(
            f"Kh√¥ng t√¨m th·∫•y file data trong {DATA_DIR}\n"
            f"Vui l√≤ng export dataframe df_merged t·ª´ notebook ra file CSV:\n"
            f"df_merged.to_csv('data/toyota_cleaned.csv', index=False, encoding='utf-8')"
        )
    data_file = max(data_files, key=lambda p: p.stat().st_mtime)
    print(f"\nüìÅ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´: {data_file.name}")
    print(f"‚ö†Ô∏è L∆∞u √Ω: File n√†y ch∆∞a ƒë∆∞·ª£c l√†m s·∫°ch. N√™n export df_merged t·ª´ notebook ra toyota_cleaned.csv")

# 1. Load data
df = pd.read_csv(data_file, encoding='utf-8')
print(f"   ‚úÖ ƒê√£ ƒë·ªçc {len(df)} d√≤ng")

# 2. Chu·∫©n b·ªã d·ªØ li·ªáu
print(f"\n1Ô∏è‚É£ CHU·∫®N B·ªä D·ªÆ LI·ªÜU:")
feature_cols = ['make', 'model', 'year', 'version', 'color', 'mileage']
target_col = 'price_vnd'

df_train = df[feature_cols + [target_col]].copy()

# Lo·∫°i b·ªè null
print(f"   - Tr∆∞·ªõc khi x·ª≠ l√Ω: {len(df_train)} d√≤ng")
df_train = df_train.dropna()
print(f"   - Sau khi lo·∫°i b·ªè null: {len(df_train)} d√≤ng")

# X·ª≠ l√Ω mileage n·∫øu l√† string (c√≥ "km")
if df_train['mileage'].dtype == 'object':
    print(f"   - ƒêang x·ª≠ l√Ω c·ªôt mileage (string -> numeric)...")
    df_train['mileage'] = df_train['mileage'].astype(str).str.replace(' km', '').str.replace(',', '').str.replace(' ', '')
    df_train['mileage'] = pd.to_numeric(df_train['mileage'], errors='coerce')
    df_train = df_train.dropna(subset=['mileage'])

# Ki·ªÉm tra v√† x·ª≠ l√Ω infinity
print(f"\n   Ki·ªÉm tra infinity v√† gi√° tr·ªã b·∫•t th∆∞·ªùng...")
for col in feature_cols + [target_col]:
    if df_train[col].dtype in [np.float64, np.float32, np.int64, np.int32]:
        inf_count = np.isinf(df_train[col]).sum()
        if inf_count > 0:
            print(f"     ‚ö†Ô∏è {col}: {inf_count} gi√° tr·ªã infinity")
            df_train = df_train[~np.isinf(df_train[col])]

print(f"   - Sau khi x·ª≠ l√Ω: {len(df_train)} d√≤ng")

# 3. Feature Engineering
print(f"\n2Ô∏è‚É£ FEATURE ENGINEERING:")

label_encoders = {}
X_encoded = pd.DataFrame()

for col in feature_cols:
    if df_train[col].dtype == 'object' or df_train[col].dtype.name == 'category':
        le = LabelEncoder()
        X_encoded[col] = le.fit_transform(df_train[col].astype(str))
        label_encoders[col] = le
        print(f"   - {col}: Label encoded ({df_train[col].nunique()} categories)")
    else:
        X_encoded[col] = df_train[col]
        print(f"   - {col}: Gi·ªØ nguy√™n (numerical)")

y = df_train[target_col].values

# Ki·ªÉm tra l·∫°i NaN/infinity sau khi encode
print(f"\n   Ki·ªÉm tra NaN/infinity sau khi encode...")
if X_encoded.isnull().sum().sum() > 0:
    print(f"     ‚ö†Ô∏è C√≥ NaN trong X_encoded")
    X_encoded = X_encoded.fillna(X_encoded.median())

if np.isinf(X_encoded.values).sum() > 0:
    print(f"     ‚ö†Ô∏è C√≥ infinity trong X_encoded")
    X_encoded = X_encoded.replace([np.inf, -np.inf], np.nan)
    X_encoded = X_encoded.fillna(X_encoded.median())

if np.isnan(y).sum() > 0:
    print(f"     ‚ö†Ô∏è C√≥ NaN trong y")
    mask = ~np.isnan(y)
    X_encoded = X_encoded[mask]
    y = y[mask]

if np.isinf(y).sum() > 0:
    print(f"     ‚ö†Ô∏è C√≥ infinity trong y")
    mask = ~np.isinf(y)
    X_encoded = X_encoded[mask]
    y = y[mask]

print(f"   - Sau khi x·ª≠ l√Ω: {len(X_encoded)} d√≤ng")

# 4. Chia train/test
print(f"\n3Ô∏è‚É£ CHIA TRAIN/TEST:")
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)

print(f"   - Train: {len(X_train)} d√≤ng")
print(f"   - Test: {len(X_test)} d√≤ng")

# Reset index ƒë·ªÉ tr√°nh l·ªói
X_train = X_train.reset_index(drop=True)
X_test = X_test.reset_index(drop=True)

# 5. Train nhi·ªÅu model
print(f"\n4Ô∏è‚É£ TRAIN NHI·ªÄU MODEL:")

models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Lasso Regression': Lasso(alpha=1.0),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
}

if XGBOOST_AVAILABLE:
    models['XGBoost'] = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)

results = {}

for name, model in models.items():
    print(f"\n   üîπ Training {name}...")
    try:
        model.fit(X_train, y_train)
        
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        
        results[name] = {
            'model': model,
            'train_mae': train_mae,
            'test_mae': test_mae,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_r2': train_r2,
            'test_r2': test_r2
        }
        
        print(f"      ‚úÖ Ho√†n th√†nh")
        print(f"         Train MAE: {train_mae:.0f} tri·ªáu")
        print(f"         Test MAE: {test_mae:.0f} tri·ªáu")
        print(f"         Test R¬≤: {test_r2:.3f}")
        
    except Exception as e:
        print(f"      ‚ùå L·ªói: {str(e)[:100]}")

# 6. So s√°nh k·∫øt qu·∫£
print(f"\n5Ô∏è‚É£ SO S√ÅNH K·∫æT QU·∫¢:")

comparison_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Train MAE': [results[m]['train_mae'] for m in results.keys()],
    'Test MAE': [results[m]['test_mae'] for m in results.keys()],
    'Train RMSE': [results[m]['train_rmse'] for m in results.keys()],
    'Test RMSE': [results[m]['test_rmse'] for m in results.keys()],
    'Train R¬≤': [results[m]['train_r2'] for m in results.keys()],
    'Test R¬≤': [results[m]['test_r2'] for m in results.keys()]
})

comparison_df = comparison_df.sort_values('Test MAE')

print("\n   üìä B·∫£ng so s√°nh:")
print(comparison_df.to_string(index=False))

# 7. Ch·ªçn model t·ªët nh·∫•t (d·ª±a tr√™n Test MAE th·∫•p nh·∫•t)
print(f"\n6Ô∏è‚É£ MODEL T·ªêT NH·∫§T:")
best_model_name = comparison_df.iloc[0]['Model']
best_model = results[best_model_name]['model']

print(f"   ‚úÖ {best_model_name}")
print(f"   - Test MAE: {results[best_model_name]['test_mae']:.0f} tri·ªáu VND")
print(f"   - Test RMSE: {results[best_model_name]['test_rmse']:.0f} tri·ªáu VND")
print(f"   - Test R¬≤: {results[best_model_name]['test_r2']:.3f}")

# Feature importance (n·∫øu c√≥)
if hasattr(best_model, 'feature_importances_'):
    print(f"\n   üìä Feature Importance:")
    feature_importance = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': best_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    print(feature_importance.to_string(index=False))

# 8. L∆∞u model t·ªët nh·∫•t v√† encoders
print(f"\n7Ô∏è‚É£ L∆ØU MODEL T·ªêT NH·∫§T V√Ä ENCODERS:")

MODELS_DIR.mkdir(exist_ok=True)

model_file = MODELS_DIR / "car_price_predictor.pkl"
encoders_file = MODELS_DIR / "label_encoders.pkl"
features_file = MODELS_DIR / "feature_columns.pkl"

# X√≥a file c≈© n·∫øu t·ªìn t·∫°i
if model_file.exists():
    model_file.unlink()
    print(f"   ‚úÖ ƒê√£ x√≥a file model c≈©")

# L∆∞u model t·ªët nh·∫•t
joblib.dump(best_model, model_file)
print(f"   ‚úÖ Model saved: {model_file}")
print(f"   - Model name: {best_model_name}")
print(f"   - Model type: {type(best_model)}")
print(f"   - Absolute path: {model_file.resolve()}")
print(f"   - Has predict: {hasattr(best_model, 'predict')}")

if encoders_file.exists():
    encoders_file.unlink()
joblib.dump(label_encoders, encoders_file)
print(f"   ‚úÖ Encoders saved: {encoders_file}")

if features_file.exists():
    features_file.unlink()
joblib.dump(feature_cols, features_file)
print(f"   ‚úÖ Features saved: {features_file}")

# L∆∞u metrics c·ªßa model t·ªët nh·∫•t
metrics_file = MODELS_DIR / "model_metrics.pkl"
metrics = {
    'test_mae': results[best_model_name]['test_mae'],
    'test_r2': results[best_model_name]['test_r2']
}
if metrics_file.exists():
    metrics_file.unlink()
joblib.dump(metrics, metrics_file)
print(f"   ‚úÖ Metrics saved: {metrics_file}")
print(f"   - Test MAE: {metrics['test_mae']:.0f} tri·ªáu")
print(f"   - Test R¬≤: {metrics['test_r2']:.3f}")

# 9. Verify model sau khi l∆∞u
print(f"\n8Ô∏è‚É£ VERIFY MODEL SAU KHI L∆ØU:")
try:
    loaded_model = joblib.load(model_file)
    print(f"   ‚úÖ Model loaded successfully")
    print(f"   - Type: {type(loaded_model)}")
    print(f"   - Has predict: {hasattr(loaded_model, 'predict')}")
    
    # Test predict
    dummy = np.array([[0, 0, 2020, 0, 0, 50000]])
    result = loaded_model.predict(dummy)
    print(f"   ‚úÖ Predict works! Result: {result[0]:.0f} tri·ªáu")
    
except Exception as e:
    print(f"   ‚ùå Verification failed: {e}")
    import traceback
    traceback.print_exc()
    raise

print(f"\n‚úÖ Ho√†n th√†nh! Model t·ªët nh·∫•t ({best_model_name}) ƒë√£ ƒë∆∞·ª£c l∆∞u")
print(f"   üìå QUAN TR·ªåNG: H√£y restart FastAPI service ƒë·ªÉ load model m·ªõi!")
print(f"   üìÅ File ƒë∆∞·ª£c l∆∞u t·∫°i: {model_file.resolve()}")